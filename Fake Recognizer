
import os
import numpy as np
import cv2
import joblib
from skimage.feature import hog
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt
from collections import Counter
import random

# Define dataset path
dataset_dir = r"C:/diploma/data/test"  # Folder with mixed images

# Allowed image file extensions
valid_extensions = ('.jpg', '.jpeg', '.png', '.bmp', '.tiff')

# Prepare dataset
image_size = (128, 128)  # Resize images for consistency
X, filenames = [], []

def augment_image(img):
    """Apply light augmentation (small noise, blur sometimes)"""
    if random.random() > 0.7:  # 30% chance of applying blur
        img = cv2.GaussianBlur(img, (3, 3), 0)

    if random.random() > 0.7:  # 30% chance of adding mild noise
        noise = np.random.normal(0, 10, img.shape).astype(np.uint8)  # Lower noise level
        img = cv2.add(img, noise)

    return img

# Loop through all images in the dataset directory
for image_name in os.listdir(dataset_dir):
    image_path = os.path.join(dataset_dir, image_name)

    # Skip non-image files
    if not image_name.lower().endswith(valid_extensions):
        print(f"Skipping non-image file: {image_name}")
        continue

    # Read and process image
    img = cv2.imread(image_path)
    if img is None:
        print(f"Skipping unreadable image: {image_path}")
        continue  # Skip if image is unreadable

    img = cv2.resize(img, image_size)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  # Convert to grayscale

    # Apply light augmentation
    img = augment_image(img)

    # Feature Extraction (Use Only HOG)
    hog_features = hog(img, pixels_per_cell=(8, 8), cells_per_block=(2, 2), feature_vector=True)

    X.append(hog_features)
    filenames.append(image_name)

X = np.array(X)

# Ensure dataset is not empty
if len(X) == 0:
    print("Error: No valid images found. Check dataset structure!")
    exit(1)

# Reduce dimensions using PCA for better clustering
pca = PCA(n_components=50)  # Reduce to 50 features
X_pca = pca.fit_transform(X)

# Apply K-Means Clustering
num_clusters = 2  # Assuming 2 clusters (one for real, one for fake)
kmeans = KMeans(n_clusters=num_clusters, random_state=42, n_init=10)
labels = kmeans.fit_predict(X_pca)

# Determine which cluster is "real" and which is "fake"
cluster_counts = Counter(labels)
real_cluster = min(cluster_counts, key=cluster_counts.get)  # Smaller cluster is assumed to be real
fake_cluster = max(cluster_counts, key=cluster_counts.get)  # Larger cluster is assumed to be fake

# Convert labels to "real" and "fake"
label_names = {real_cluster: "real", fake_cluster: "fake"}
labeled_results = [(filename, label_names[label]) for filename, label in zip(filenames, labels)]

# Print cluster distribution
print("\nCluster Distribution:", Counter([label for _, label in labeled_results]))

# âœ… *Save results with "real" and "fake" labels*
output_file = os.path.join(dataset_dir, "cluster_results.txt")

with open(output_file, "w") as f:
    for filename, cluster_label in labeled_results:
        f.write(f"{filename},{cluster_label}\n")

print(f"\nClustering complete! Results saved in {output_file}")

# Plot clusters
plt.scatter(X_pca[:, 0], X_pca[:, 1], c=labels, cmap='viridis', edgecolors='k')
plt.title("K-Means Clustering of Images")
plt.xlabel("PCA Feature 1")
plt.ylabel("PCA Feature 2")
plt.show()
